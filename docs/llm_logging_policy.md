# Политика логирования LLM-вызовов и хранения истории

Документ фиксирует минимальный формат логирования LLM-вызовов и базовую политику хранения истории, чтобы аналитика, экспорт и отладка были предсказуемыми уже в MVP.

## 1) Формат логирования LLM-вызовов

Минимальный набор полей для записи в `llm_call_logs` (или эквивалентную таблицу):

- `provider` — `openai` | `gemini`
- `model`
- `purpose` — `report` | `followup` | `repair`
- `latency_ms`
- `ok` (bool)
- `error_text` (nullable)
- `prompt_tokens` / `output_tokens` / `total_tokens` (nullable)
- `request_id` (nullable)
- `created_at`

Рекомендации:
- Вести логирование на каждом вызове LLM, включая ретраи.
- Явно отмечать, был ли результат валидным JSON (для `pdf_blocks`).
- Хранить агрегации по дням (через stats) отдельно, чтобы не сканировать полный лог.

## 2) Политика хранения истории

MVP требует бессрочного хранения истории переписки (входящие/исходящие сообщения и события).
При этом важно не хранить чувствительные данные сверх необходимого:

- **Не сохранять** API-ключи и любые секреты.
- Промпты и сырой ответ LLM (`raw_text`) можно хранить, но рекомендуется добавить флаг `LLM_LOG_PROMPTS_ENABLED`.
- В случае отключения логирования промптов хранить только метаданные (provider/model/latency/usage).

## 3) Экспорт и аналитика

Для упрощения аналитики и экспорта следует поддерживать:

- Экспорт `llm_call_logs` в CSV/JSON по диапазону дат.
- Признак `ok=false` и `error_text` для анализа ошибок.
- Возможность сверки `llm_call_logs` с `reports` и `report_sessions` через `report_id`/`session_id`.

## 4) Рекомендации по безопасности

- Маскировать персональные данные в логах, если они не нужны для диагностики.
- Ограничить доступ к логам и экспортам только администраторам.
- Настроить ротацию логов приложения (например, еженедельно) — это не отменяет хранение в БД.
